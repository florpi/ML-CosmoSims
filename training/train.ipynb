{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "# import torch.utils.data.distributed\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.datasets as datasets\n",
    "# import torchvision.models as models\n",
    "\n",
    "from torch.utils import data\n",
    "import random\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from args import args\n",
    "from train_f import *\n",
    "from Dataset import Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[     0., 999999., 999999.],\n",
       "           [999999., 999999., 999999.],\n",
       "           [999999., 999999., 999999.]],\n",
       "\n",
       "          [[999999., 999999., 999999.],\n",
       "           [999999., 999999., 999999.],\n",
       "           [999999., 999999., 999999.]],\n",
       "\n",
       "          [[999999., 999999., 999999.],\n",
       "           [999999., 999999., 999999.],\n",
       "           [999999., 999999., 999999.]]],\n",
       "\n",
       "\n",
       "         [[[999999.,      0.,      0.],\n",
       "           [     0.,      0.,      0.],\n",
       "           [     0.,      0.,      0.]],\n",
       "\n",
       "          [[     0.,      0.,      0.],\n",
       "           [     0.,      0.,      0.],\n",
       "           [     0.,      0.,      0.]],\n",
       "\n",
       "          [[     0.,      0.,      0.],\n",
       "           [     0.,      0.,      0.],\n",
       "           [     0.,      0.,      0.]]]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.Tensor(np.zeros((1,2,3,3,3)))\n",
    "pred[0,0,:,:,:] = 999999\n",
    "#pred[0,1,1,1] = 1\n",
    "pred[0,1,0,0,0] = 999999\n",
    "pred[0,0,0,0,0] = 0\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       "\n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       "\n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target= torch.Tensor(np.zeros((1,3,3,3))).long()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       "\n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       "\n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]]]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = F.softmax(pred, dim=1)\n",
    "predicted = outputs.max(1)[1]\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(pred, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yqloss(pred, target):\n",
    "    criterion = nn.CrossEntropyLoss(weight = torch.Tensor([0.5,0.5]))\n",
    "    loss_nn = criterion(pred, target)\n",
    "    loss_blob = \n",
    "    \n",
    "    return loss\n",
    "yqloss(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f= open(\"guru99.txt\",\"a+\")\n",
    "f.write('\"arguments: %s\" %(params)\\n')\n",
    "f.write('Test Loss {BEST_VAL_LOSS:.4f},  Test Accuracy {BEST_ACC:.4f},  Test Recall {BEST_RECALL:.4f},  \\\n",
    "Precision {BEST_PRECISION:.4f}   F1 score  {BEST_F1SCORE:.4f}\\t'.format( \\\n",
    "            BEST_VAL_LOSS=BEST_VAL_LOSS,BEST_ACC=BEST_ACC, BEST_RECALL = BEST_RECALLÂ´, BEST_PRECISION = BEST_PRECISION, BEST_F1SCORE =  BEST_F1SCORE)))\n",
    "f.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution_loss_prep(pred,Y):\n",
    "    fixed_ones_conv = nn.Conv3d(1,1,kernel_size = 3, padding = 1)\n",
    "    nn.init.constant_(fixed_ones_conv.weight,1)\n",
    "    fixed_ones_conv.weight.requires_grad = False\n",
    "    conv_pred = fixed_ones_conv(pred)\n",
    "    conv_Y = fixed_ones_conv(Y)\n",
    "    return conv_pred, conv_Y\n",
    "\n",
    "# Convolution loss for MSE, use together with weight\n",
    "def convolution_loss(pred,Y, weight_ratio):\n",
    "    weight_mse_loss = weighted_nn_square_loss(weight_ratio)\n",
    "    conv_pred, conv_Y = convolution_loss_prep(pred,Y)\n",
    "    return weight_mse_loss(con_pred,con_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_nn_loss(weight_ratio):\n",
    "    def weighted(X,Y):\n",
    "        base_loss = F.mse_loss(X,Y,reduction = 'sum')\n",
    "        index = Y > 0\n",
    "        plus_loss = F.mse_loss(X[index],Y[index], reduction = 'sum') if index.any() > 0 else 0\n",
    "        total_loss = base_loss + (weight_ratio -1) * plus_loss\n",
    "        return total_loss/X.shape[0]\n",
    "    return weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor([3,2,1, 0, 0])\n",
    "b = torch.Tensor([1,2,100, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1961.8000)\n",
      "tensor(1961.8000)\n"
     ]
    }
   ],
   "source": [
    "criterion1 = weighted_nn_loss(1)\n",
    "criterion2 = nn.MSELoss()\n",
    "print(criterion1(a,b))\n",
    "print(criterion2(a,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        \n",
    "        super(Baseline, self).__init__()\n",
    "        '''\n",
    "        torch.nn.Conv3d: input(N,C,D,H,W)\n",
    "                            output(N,C,Dout,Hout,Wout) \n",
    "        torch.nn.AvgPool3d: input(N,C,D,H,W)\n",
    "                            output(N,C,Dout,Hout,Wout)     \n",
    "        '''\n",
    "        '''\n",
    "        nn.Conv3d(in_channels, out_channels, kernel_size)\n",
    "        nn.AvgPool3d()\n",
    "        '''\n",
    "        self.draft_model = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "#             nn.AvgPool3d(3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(in_ch, out_ch, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "#             nn.AvgPool3d(3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, cube):\n",
    "        cube = self.draft_model(cube)\n",
    "        return cube\n",
    "    \n",
    "class SimpleUnet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        \n",
    "        super(SimpleUnet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.Simple_Unet = nn.Sequential(\n",
    "            self.conv_layer(self.in_channels, 16),\n",
    "            self.conv_layer(16, 16),\n",
    "            nn.AvgPool3d(2),\n",
    "            self.conv_layer(16,32),\n",
    "            nn.AvgPool3d(2),\n",
    "            self.conv_layer(32,64),\n",
    "            self.up_conv_layer(64, 64, 3),\n",
    "            self.conv_layer(64, 32),\n",
    "            self.up_conv_layer(32, 32, 3),\n",
    "            self.conv_layer(32, 16),\n",
    "            self.up_conv_layer(16, 16, 2),\n",
    "            self.conv_layer(16, 8),\n",
    "            self.up_conv_layer(8, 8, 2),\n",
    "            self.conv_layer(8, 4),\n",
    "            self.conv_layer(4, 1)\n",
    "        )\n",
    "    \n",
    "    def conv_layer(self, in_channels, out_channels, kernel_size=3, stride=1, padding=0, bias=True):\n",
    "        layers = nn.Sequential(\n",
    "        nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "        nn.BatchNorm3d(out_channels),\n",
    "        nn.LeakyReLU())\n",
    "        return layers\n",
    "    \n",
    "    def up_conv_layer(self, in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, bias=True):\n",
    "        layers = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            # should be feat_in*2 or feat_in\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.LeakyReLU())\n",
    "        return layers\n",
    "    \n",
    "    \n",
    "    def forward(self, cube):\n",
    "        cube = self.Simple_Unet(cube)\n",
    "        return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "\n",
    "\n",
    "        # add a dimension, from (1, 32, 32, 32) to (1,1,32,32,32)\n",
    "        input = input.unsqueeze(dim = 1).to(device).float()\n",
    "        target = target.unsqueeze(dim = 1).to(device).float()\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.train()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input = input.unsqueeze(dim = 1).to(device).float()\n",
    "            target = target.unsqueeze(dim = 1).to(device).float()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            \n",
    "        print('Test: Time {batch_time.val:.3f} \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'\n",
    "              'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(batch_time=batch_time, loss=losses))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index for the cube, each tuple corresponds to a cude\n",
    "train_data = [(800, 640, 224)]\n",
    "val_data = [(800, 640, 224)]\n",
    "test_data = [(800, 640, 224)]\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pos=list(np.arange(0,1024,32))\n",
    "# ranges=list(product(pos,repeat=3))\n",
    "# # random.shuffle(ranges)\n",
    "# train_data = ranges[:int(np.round(len(ranges)*0.6))]\n",
    "# val_data=ranges[int(np.round(len(ranges)*0.6)):int(np.round(len(ranges)*0.8))]\n",
    "# test_data = ranges[int(np.round(len(ranges)*0.8)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'batch_size': 50,\n",
    "          'shuffle': False,\n",
    "          #'shuffle': True,\n",
    "          'num_workers':20}\n",
    "max_epochs = 100\n",
    "\n",
    "training_set, validation_set = Dataset(train_data), Dataset(val_data)\n",
    "testing_set= Dataset(test_data)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n",
    "testing_generator = data.DataLoader(testing_set, **params)\n",
    "\n",
    "for i, (dark,full) in enumerate(testing_generator):\n",
    "    dark=dark\n",
    "    full=full\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim = 1\n",
    "model = SimpleUnet(dim).to(device)\n",
    "criterion = nn.MSELoss().to(device) #yueqiu\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ys3202/.conda/envs/dark/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/1]\tTime 0.340 (0.340)\tLoss 0.0651 (0.0651)\t\n",
      "Test: Time 0.156 \t\t\t\t\t\t\t\t\t\tLoss 21.5622 (21.5622)\t\n",
      "Epoch: [1][0/1]\tTime 0.281 (0.281)\tLoss 21.5622 (21.5622)\t\n",
      "Test: Time 0.164 \t\t\t\t\t\t\t\t\t\tLoss 1303.5524 (1303.5524)\t\n",
      "Epoch: [2][0/1]\tTime 0.293 (0.293)\tLoss 1303.5524 (1303.5524)\t\n",
      "Test: Time 0.161 \t\t\t\t\t\t\t\t\t\tLoss 58937.8438 (58937.8438)\t\n",
      "Epoch: [3][0/1]\tTime 0.285 (0.285)\tLoss 58937.8438 (58937.8438)\t\n",
      "Test: Time 0.167 \t\t\t\t\t\t\t\t\t\tLoss 16216511.0000 (16216511.0000)\t\n",
      "Epoch: [4][0/1]\tTime 0.293 (0.293)\tLoss 16216511.0000 (16216511.0000)\t\n",
      "Test: Time 0.179 \t\t\t\t\t\t\t\t\t\tLoss 3803902208.0000 (3803902208.0000)\t\n",
      "Epoch: [5][0/1]\tTime 0.284 (0.284)\tLoss 3803902208.0000 (3803902208.0000)\t\n",
      "Test: Time 0.185 \t\t\t\t\t\t\t\t\t\tLoss 658882363392.0000 (658882363392.0000)\t\n",
      "Epoch: [6][0/1]\tTime 0.300 (0.300)\tLoss 658882363392.0000 (658882363392.0000)\t\n",
      "Test: Time 0.189 \t\t\t\t\t\t\t\t\t\tLoss 237700653252608.0000 (237700653252608.0000)\t\n",
      "Epoch: [7][0/1]\tTime 0.327 (0.327)\tLoss 237700653252608.0000 (237700653252608.0000)\t\n",
      "Test: Time 0.184 \t\t\t\t\t\t\t\t\t\tLoss 20743010559983616.0000 (20743010559983616.0000)\t\n",
      "Epoch: [8][0/1]\tTime 0.297 (0.297)\tLoss 20743010559983616.0000 (20743010559983616.0000)\t\n",
      "Test: Time 0.175 \t\t\t\t\t\t\t\t\t\tLoss 1550701297664000.0000 (1550701297664000.0000)\t\n",
      "Epoch: [9][0/1]\tTime 0.299 (0.299)\tLoss 1550701297664000.0000 (1550701297664000.0000)\t\n",
      "Test: Time 0.176 \t\t\t\t\t\t\t\t\t\tLoss 11115662051115008.0000 (11115662051115008.0000)\t\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(training_generator, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    validate(validation_generator, model, criterion)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(800, 640, 224)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
